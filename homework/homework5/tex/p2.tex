\problem{}
Suppose that for a certain decision problem, we have an algorithm which computes the correct answer with a probability  at least 2/3 on any instance.  We wish to reduce the error probability by running the algorithm $n$ times on the same input, using independent randomness between trials, and taking the most common result as the final answer. Using Chernoff bounds, provide an upper bound on the probability that this modified algorithm produces an incorrect result.

\solution{}

Let $X_i$ be the indicator of the $i$-th time's answer. i.e.
$$X_{i}=\begin{cases}1,\text{the $i$-th time's answer is the correct answer}\\0,\text{otherwise}\end{cases}$$

If we consider the upper bound of the probability that prodeces an incorrect result, i.e.
$$P(X_i=1)=\dfrac{2}{3}, P(X_i=0)=\dfrac{1}{3}$$
Then we can get the expectation of $X_i$ is $\mathbb{E}(X_i)=\dfrac{2}{3}$.

Then we define the total number of correct answers as $$X=\sum_{i=1}^nX_i$$
From the linearity of expectation, we have
$$\mathbb{E}(X)=\mathbb{E}\left(\sum_{i=1}^n{X_i}\right)=\sum_{i=1}^n\mathbb{E}(X_i)=\dfrac{2n}{3}$$

According to Chernoff bounds:
$$\text{For } 0\leq\delta\leq 1,\ \Pr(X\leq(1-\delta)\mathbb{E}(X))\leq \exp\left(-\dfrac{\delta^2\mathbb{E}(X)}{2}\right)$$

If we want to get the upper bound of the probability that this modified algorithm produces an incorrect result, we could know that the number of the correct answers is at most $\dfrac{n}{2}$, i.e.
$$\Pr\left(X\leq\dfrac{n}{2}\right)=\Pr\left(X\leq\dfrac{3}{4}\cdot\dfrac{2n}{3}\right)\leq \exp\left(-\dfrac{1}{2}\cdot\dfrac{2n}{3}\cdot\dfrac{1}{4}\cdot\dfrac{1}{4}\right)=\exp\left(-\dfrac{n}{48}\right)$$

Which uses the Chernoff bounds mentioned above, where $\delta=\dfrac{1}{4}$.\\
So above all, the upper bound of the probability that this modified algorithm produces an incorrect result is $\exp\left(-\dfrac{n}{48}\right)$.

\newpage